{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to use the Kaggle API from Colab",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/drift/blob/main/Another_model_0619.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DIf2PtekjPtY"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing the [Kaggle API](https://github.com/Kaggle/kaggle-api) in Colab"
      ]
    },
    {
      "metadata": {
        "id": "OppyMnCuWjzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3e44bc-c84e-4c4c-d831-3ef2d7aa9593"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hMY4CFezjcG-"
      },
      "cell_type": "markdown",
      "source": [
        "# Authenticating with Kaggle using kaggle.json\n",
        "\n",
        "Navigate to https://www.kaggle.com. Then go to the [Account tab of your user profile](https://www.kaggle.com/me/account) and select Create API Token. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "\n",
        "Then run the cell below to upload kaggle.json to your Colab runtime."
      ]
    },
    {
      "metadata": {
        "id": "0HtGf0HEXEa5",
        "outputId": "b36383f2-8fb6-40e0-fcde-3e1fb7e32fe4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6dfec58-b6c0-4b37-83ff-582d5b60b994\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d6dfec58-b6c0-4b37-83ff-582d5b60b994\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 66 bytes\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HMk7Zz4ZkpCe"
      },
      "cell_type": "markdown",
      "source": [
        "# Using the Kaggle API\n",
        "\n",
        "For a more complete list of what you can do with the API, visit https://github.com/Kaggle/kaggle-api."
      ]
    },
    {
      "metadata": {
        "id": "SHVqmMXfilWG"
      },
      "cell_type": "markdown",
      "source": [
        "## Listing competitions"
      ]
    },
    {
      "metadata": {
        "id": "Oqt7Yfi5aQuM",
        "outputId": "3c715653-e76c-476e-c944-8de323d69a65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions list"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "contradictory-my-dear-watson                   2030-07-01 23:59:00  Getting Started     Prizes         41           False  \n",
            "gan-getting-started                            2030-07-01 23:59:00  Getting Started     Prizes        131           False  \n",
            "store-sales-time-series-forecasting            2030-06-30 23:59:00  Getting Started  Knowledge        676           False  \n",
            "tpu-getting-started                            2030-06-03 23:59:00  Getting Started  Knowledge        134           False  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       1551           False  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge      14101           False  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4239           False  \n",
            "connectx                                       2030-01-01 00:00:00  Getting Started  Knowledge        192           False  \n",
            "nlp-getting-started                            2030-01-01 00:00:00  Getting Started  Knowledge        951           False  \n",
            "spaceship-titanic                              2030-01-01 00:00:00  Getting Started  Knowledge       2307           False  \n",
            "competitive-data-science-predict-future-sales  2022-12-31 23:59:00  Playground           Kudos      14967           False  \n",
            "amex-default-prediction                        2022-08-24 23:59:00  Featured          $100,000       1368           False  \n",
            "feedback-prize-effectiveness                   2022-08-23 23:59:00  Featured           $55,000        385           False  \n",
            "AI4Code                                        2022-08-11 23:59:00  Featured          $150,000        574           False  \n",
            "smartphone-decimeter-2022                      2022-07-29 23:59:00  Research           $10,000        290           False  \n",
            "ubiquant-market-prediction                     2022-07-18 23:59:00  Featured          $100,000       2459           False  \n",
            "uw-madison-gi-tract-image-segmentation         2022-07-14 23:59:00  Research           $25,000       1207           False  \n",
            "kore-2022                                      2022-07-12 23:59:00  Featured           $15,000        365           False  \n",
            "foursquare-location-matching                   2022-07-07 23:59:00  Featured           $25,000        895           False  \n",
            "jpx-tokyo-stock-exchange-prediction            2022-07-05 23:59:00  Featured           $63,000       1698           False  \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dNke00r6ig3h"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading a dataset"
      ]
    },
    {
      "metadata": {
        "id": "Aojvqv8Gaf8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e05f1b-97b5-48b3-f3d0-46a405cb5c57"
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets download \"kartik2112/fraud-detection\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fraud-detection.zip to /content\n",
            " 98% 197M/202M [00:01<00:00, 112MB/s]\n",
            "100% 202M/202M [00:01<00:00, 132MB/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DsyV01gDaxls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92959e6-0197-4792-89d6-fb68f829e361"
      },
      "cell_type": "code",
      "source": [
        "!unzip fraud-detection.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fraud-detection.zip\n",
            "  inflating: fraudTest.csv           \n",
            "  inflating: fraudTrain.csv          \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "L7ZmFbHybsPk"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "train = pd.read_csv('fraudTrain.csv')\n",
        "test = pd.read_csv('fraudTest.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatenate the splitted data\n",
        "df = pd.concat([train,test],ignore_index=True)\n",
        "df.drop('Unnamed: 0',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "LHcma5xSeX69"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Fzv0Q3kDe1fj",
        "outputId": "d744629c-9a9a-49c7-b25b-6b9bc1a07723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  trans_date_trans_time            cc_num                            merchant  \\\n",
              "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
              "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
              "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
              "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
              "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
              "\n",
              "        category     amt      first     last gender  \\\n",
              "0       misc_net    4.97   Jennifer    Banks      F   \n",
              "1    grocery_pos  107.23  Stephanie     Gill      F   \n",
              "2  entertainment  220.11     Edward  Sanchez      M   \n",
              "3  gas_transport   45.00     Jeremy    White      M   \n",
              "4       misc_pos   41.96      Tyler   Garcia      M   \n",
              "\n",
              "                         street            city  ...      lat      long  \\\n",
              "0                561 Perry Cove  Moravian Falls  ...  36.0788  -81.1781   \n",
              "1  43039 Riley Greens Suite 393          Orient  ...  48.8878 -118.2105   \n",
              "2      594 White Dale Suite 530      Malad City  ...  42.1808 -112.2620   \n",
              "3   9443 Cynthia Court Apt. 038         Boulder  ...  46.2306 -112.1138   \n",
              "4              408 Bradley Rest        Doe Hill  ...  38.4207  -79.4629   \n",
              "\n",
              "   city_pop                                job         dob  \\\n",
              "0      3495          Psychologist, counselling  1988-03-09   \n",
              "1       149  Special educational needs teacher  1978-06-21   \n",
              "2      4154        Nature conservation officer  1962-01-19   \n",
              "3      1939                    Patent attorney  1967-01-12   \n",
              "4        99     Dance movement psychotherapist  1986-03-28   \n",
              "\n",
              "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
              "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
              "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
              "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
              "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
              "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
              "\n",
              "   is_fraud  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7586301d-33b8-4d6c-a4df-b362a9f5a658\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trans_date_trans_time</th>\n",
              "      <th>cc_num</th>\n",
              "      <th>merchant</th>\n",
              "      <th>category</th>\n",
              "      <th>amt</th>\n",
              "      <th>first</th>\n",
              "      <th>last</th>\n",
              "      <th>gender</th>\n",
              "      <th>street</th>\n",
              "      <th>city</th>\n",
              "      <th>...</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>city_pop</th>\n",
              "      <th>job</th>\n",
              "      <th>dob</th>\n",
              "      <th>trans_num</th>\n",
              "      <th>unix_time</th>\n",
              "      <th>merch_lat</th>\n",
              "      <th>merch_long</th>\n",
              "      <th>is_fraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-01 00:00:18</td>\n",
              "      <td>2703186189652095</td>\n",
              "      <td>fraud_Rippin, Kub and Mann</td>\n",
              "      <td>misc_net</td>\n",
              "      <td>4.97</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>Banks</td>\n",
              "      <td>F</td>\n",
              "      <td>561 Perry Cove</td>\n",
              "      <td>Moravian Falls</td>\n",
              "      <td>...</td>\n",
              "      <td>36.0788</td>\n",
              "      <td>-81.1781</td>\n",
              "      <td>3495</td>\n",
              "      <td>Psychologist, counselling</td>\n",
              "      <td>1988-03-09</td>\n",
              "      <td>0b242abb623afc578575680df30655b9</td>\n",
              "      <td>1325376018</td>\n",
              "      <td>36.011293</td>\n",
              "      <td>-82.048315</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-01 00:00:44</td>\n",
              "      <td>630423337322</td>\n",
              "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
              "      <td>grocery_pos</td>\n",
              "      <td>107.23</td>\n",
              "      <td>Stephanie</td>\n",
              "      <td>Gill</td>\n",
              "      <td>F</td>\n",
              "      <td>43039 Riley Greens Suite 393</td>\n",
              "      <td>Orient</td>\n",
              "      <td>...</td>\n",
              "      <td>48.8878</td>\n",
              "      <td>-118.2105</td>\n",
              "      <td>149</td>\n",
              "      <td>Special educational needs teacher</td>\n",
              "      <td>1978-06-21</td>\n",
              "      <td>1f76529f8574734946361c461b024d99</td>\n",
              "      <td>1325376044</td>\n",
              "      <td>49.159047</td>\n",
              "      <td>-118.186462</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-01 00:00:51</td>\n",
              "      <td>38859492057661</td>\n",
              "      <td>fraud_Lind-Buckridge</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>220.11</td>\n",
              "      <td>Edward</td>\n",
              "      <td>Sanchez</td>\n",
              "      <td>M</td>\n",
              "      <td>594 White Dale Suite 530</td>\n",
              "      <td>Malad City</td>\n",
              "      <td>...</td>\n",
              "      <td>42.1808</td>\n",
              "      <td>-112.2620</td>\n",
              "      <td>4154</td>\n",
              "      <td>Nature conservation officer</td>\n",
              "      <td>1962-01-19</td>\n",
              "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
              "      <td>1325376051</td>\n",
              "      <td>43.150704</td>\n",
              "      <td>-112.154481</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-01 00:01:16</td>\n",
              "      <td>3534093764340240</td>\n",
              "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
              "      <td>gas_transport</td>\n",
              "      <td>45.00</td>\n",
              "      <td>Jeremy</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>9443 Cynthia Court Apt. 038</td>\n",
              "      <td>Boulder</td>\n",
              "      <td>...</td>\n",
              "      <td>46.2306</td>\n",
              "      <td>-112.1138</td>\n",
              "      <td>1939</td>\n",
              "      <td>Patent attorney</td>\n",
              "      <td>1967-01-12</td>\n",
              "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
              "      <td>1325376076</td>\n",
              "      <td>47.034331</td>\n",
              "      <td>-112.561071</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-01 00:03:06</td>\n",
              "      <td>375534208663984</td>\n",
              "      <td>fraud_Keeling-Crist</td>\n",
              "      <td>misc_pos</td>\n",
              "      <td>41.96</td>\n",
              "      <td>Tyler</td>\n",
              "      <td>Garcia</td>\n",
              "      <td>M</td>\n",
              "      <td>408 Bradley Rest</td>\n",
              "      <td>Doe Hill</td>\n",
              "      <td>...</td>\n",
              "      <td>38.4207</td>\n",
              "      <td>-79.4629</td>\n",
              "      <td>99</td>\n",
              "      <td>Dance movement psychotherapist</td>\n",
              "      <td>1986-03-28</td>\n",
              "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
              "      <td>1325376186</td>\n",
              "      <td>38.674999</td>\n",
              "      <td>-78.632459</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7586301d-33b8-4d6c-a4df-b362a9f5a658')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7586301d-33b8-4d6c-a4df-b362a9f5a658 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7586301d-33b8-4d6c-a4df-b362a9f5a658');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of the data (rows,columns)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "MXfFCI15e27z",
        "outputId": "d0facb42-13d8-4b22-eec6-38926d6b47cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1852394, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding dtypes and other basic info about the features\n",
        "df.info()"
      ],
      "metadata": {
        "id": "WO8uiCuce6u2",
        "outputId": "fc3c425c-97bd-4b97-b1c9-9233d7d9940a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1852394 entries, 0 to 1852393\n",
            "Data columns (total 22 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   trans_date_trans_time  object \n",
            " 1   cc_num                 int64  \n",
            " 2   merchant               object \n",
            " 3   category               object \n",
            " 4   amt                    float64\n",
            " 5   first                  object \n",
            " 6   last                   object \n",
            " 7   gender                 object \n",
            " 8   street                 object \n",
            " 9   city                   object \n",
            " 10  state                  object \n",
            " 11  zip                    int64  \n",
            " 12  lat                    float64\n",
            " 13  long                   float64\n",
            " 14  city_pop               int64  \n",
            " 15  job                    object \n",
            " 16  dob                    object \n",
            " 17  trans_num              object \n",
            " 18  unix_time              int64  \n",
            " 19  merch_lat              float64\n",
            " 20  merch_long             float64\n",
            " 21  is_fraud               int64  \n",
            "dtypes: float64(5), int64(5), object(12)\n",
            "memory usage: 310.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib.pyplot as plt###\n",
        "                               ### Visualisation tools\n",
        "import seaborn as sns          ###\n",
        "\n",
        "from sklearn.linear_model import LinearRegression,LogisticRegression,SGDRegressor , Ridge,Lasso\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix\n",
        "from sklearn.metrics import classification_report,roc_curve,roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "_AGpHx6QfJ9w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dividing data into categorical and numerical\n",
        "df_cat = df.select_dtypes(include = 'object')\n",
        "df_num = df.select_dtypes(exclude = 'object')\n",
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "BizQmguge-3K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['gender_le']  = le.fit_transform(df['gender'])"
      ],
      "metadata": {
        "id": "p6SZ9_aJfSg0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperating  numerical from nominal\n",
        "# cutting off some data to avoid heavy cpu usage\n",
        "df2 = df.select_dtypes(exclude = 'object')\n",
        "#df2 = df2.loc[:149999]"
      ],
      "metadata": {
        "id": "3sUrHipofeqQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the feature which is not useful for data analysis\n",
        "df2 = df2.drop(['cc_num'],axis=1)\n",
        "# seperating target and independent features\n",
        "x = df2.drop('is_fraud',axis=1)\n",
        "y = df2['is_fraud']"
      ],
      "metadata": {
        "id": "oyNx2-znfj25"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_num = df_num.drop(['cc_num'],axis=1)\n",
        "df_num = df_num.drop('is_fraud',axis=1)"
      ],
      "metadata": {
        "id": "b2QjqP_rhlMM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_num.columns"
      ],
      "metadata": {
        "id": "ad3_wR09hpp0",
        "outputId": "e8e9b846-092d-4463-c9a5-14bb14a25bc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['amt', 'zip', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat',\n",
              "       'merch_long'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "yyPmHWEinEt5",
        "outputId": "2f5aeadb-9ae1-4853-b90e-db6ba5e9a9cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1852394, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = x[0:300000]\n",
        "train_y = y[0:300000]\n"
      ],
      "metadata": {
        "id": "eUFSCpd6flER"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x"
      ],
      "metadata": {
        "id": "MrjXRQpKhQq7",
        "outputId": "14fffa97-32d1-4845-e9b1-40034fb0c685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           amt    zip      lat      long  city_pop   unix_time  merch_lat  \\\n",
              "0         4.97  28654  36.0788  -81.1781      3495  1325376018  36.011293   \n",
              "1       107.23  99160  48.8878 -118.2105       149  1325376044  49.159047   \n",
              "2       220.11  83252  42.1808 -112.2620      4154  1325376051  43.150704   \n",
              "3        45.00  59632  46.2306 -112.1138      1939  1325376076  47.034331   \n",
              "4        41.96  24433  38.4207  -79.4629        99  1325376186  38.674999   \n",
              "...        ...    ...      ...       ...       ...         ...        ...   \n",
              "299995   96.03  25106  38.8265  -82.1364       642  1338048681  39.298162   \n",
              "299996   59.77  63021  38.5770  -90.5255     92608  1338048685  39.339959   \n",
              "299997   77.82  73754  36.3850  -98.0727      1078  1338048717  36.545200   \n",
              "299998   53.20  27522  36.1124  -78.6476     12335  1338048723  36.078714   \n",
              "299999   78.53  54896  45.8327  -91.0144      1478  1338048746  45.181078   \n",
              "\n",
              "        merch_long  gender_le  \n",
              "0       -82.048315          0  \n",
              "1      -118.186462          0  \n",
              "2      -112.154481          1  \n",
              "3      -112.561071          1  \n",
              "4       -78.632459          1  \n",
              "...            ...        ...  \n",
              "299995  -82.030474          0  \n",
              "299996  -89.859340          1  \n",
              "299997  -98.854027          1  \n",
              "299998  -78.024839          0  \n",
              "299999  -90.340056          0  \n",
              "\n",
              "[300000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14e3ecff-3c7d-4c33-a72b-47e3e84f6f36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amt</th>\n",
              "      <th>zip</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>city_pop</th>\n",
              "      <th>unix_time</th>\n",
              "      <th>merch_lat</th>\n",
              "      <th>merch_long</th>\n",
              "      <th>gender_le</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.97</td>\n",
              "      <td>28654</td>\n",
              "      <td>36.0788</td>\n",
              "      <td>-81.1781</td>\n",
              "      <td>3495</td>\n",
              "      <td>1325376018</td>\n",
              "      <td>36.011293</td>\n",
              "      <td>-82.048315</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>107.23</td>\n",
              "      <td>99160</td>\n",
              "      <td>48.8878</td>\n",
              "      <td>-118.2105</td>\n",
              "      <td>149</td>\n",
              "      <td>1325376044</td>\n",
              "      <td>49.159047</td>\n",
              "      <td>-118.186462</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220.11</td>\n",
              "      <td>83252</td>\n",
              "      <td>42.1808</td>\n",
              "      <td>-112.2620</td>\n",
              "      <td>4154</td>\n",
              "      <td>1325376051</td>\n",
              "      <td>43.150704</td>\n",
              "      <td>-112.154481</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45.00</td>\n",
              "      <td>59632</td>\n",
              "      <td>46.2306</td>\n",
              "      <td>-112.1138</td>\n",
              "      <td>1939</td>\n",
              "      <td>1325376076</td>\n",
              "      <td>47.034331</td>\n",
              "      <td>-112.561071</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.96</td>\n",
              "      <td>24433</td>\n",
              "      <td>38.4207</td>\n",
              "      <td>-79.4629</td>\n",
              "      <td>99</td>\n",
              "      <td>1325376186</td>\n",
              "      <td>38.674999</td>\n",
              "      <td>-78.632459</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299995</th>\n",
              "      <td>96.03</td>\n",
              "      <td>25106</td>\n",
              "      <td>38.8265</td>\n",
              "      <td>-82.1364</td>\n",
              "      <td>642</td>\n",
              "      <td>1338048681</td>\n",
              "      <td>39.298162</td>\n",
              "      <td>-82.030474</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299996</th>\n",
              "      <td>59.77</td>\n",
              "      <td>63021</td>\n",
              "      <td>38.5770</td>\n",
              "      <td>-90.5255</td>\n",
              "      <td>92608</td>\n",
              "      <td>1338048685</td>\n",
              "      <td>39.339959</td>\n",
              "      <td>-89.859340</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299997</th>\n",
              "      <td>77.82</td>\n",
              "      <td>73754</td>\n",
              "      <td>36.3850</td>\n",
              "      <td>-98.0727</td>\n",
              "      <td>1078</td>\n",
              "      <td>1338048717</td>\n",
              "      <td>36.545200</td>\n",
              "      <td>-98.854027</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299998</th>\n",
              "      <td>53.20</td>\n",
              "      <td>27522</td>\n",
              "      <td>36.1124</td>\n",
              "      <td>-78.6476</td>\n",
              "      <td>12335</td>\n",
              "      <td>1338048723</td>\n",
              "      <td>36.078714</td>\n",
              "      <td>-78.024839</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299999</th>\n",
              "      <td>78.53</td>\n",
              "      <td>54896</td>\n",
              "      <td>45.8327</td>\n",
              "      <td>-91.0144</td>\n",
              "      <td>1478</td>\n",
              "      <td>1338048746</td>\n",
              "      <td>45.181078</td>\n",
              "      <td>-90.340056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300000 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14e3ecff-3c7d-4c33-a72b-47e3e84f6f36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14e3ecff-3c7d-4c33-a72b-47e3e84f6f36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14e3ecff-3c7d-4c33-a72b-47e3e84f6f36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the data\n",
        "ss = StandardScaler()\n",
        "train_x[df_num.columns] = ss.fit_transform(train_x[df_num.columns])\n"
      ],
      "metadata": {
        "id": "t1xDGIh7hw1u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.value_counts()"
      ],
      "metadata": {
        "id": "EKwDAePZi7M5",
        "outputId": "bbfb3933-b573-4371-e105-c33460a80ad9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    297745\n",
              "1      2255\n",
              "Name: is_fraud, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random"
      ],
      "metadata": {
        "id": "p71_5dSogH23"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 500\n",
        "\n",
        "model_c = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(train_x.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "opt = optimizers.Adam(learning_rate=0.000001)\n",
        "model_c.compile(optimizer=opt,\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['acc'])\n",
        "print(model_c.summary())\n",
        "#hist = model_c.fit(dx, metric_c[:,0], validation_split=0.2, batch_size=400, epochs=epochs,shuffle=False,verbose=0,callbacks=[early_stop,VerboseCallback(epochs)]) #, callbacks=[es_callback])\n",
        "hist = model_c.fit(train_x, train_y, validation_split=0.2, \n",
        "                   batch_size=5000, epochs=epochs,shuffle=False,use_multiprocessing=False,\n",
        "                   verbose=1, callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "2YQtp_A_gMno",
        "outputId": "7554688e-7d2e-4630-e784-f6801aee1559",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               1280      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,601\n",
            "Trainable params: 9,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/500\n",
            "48/48 [==============================] - 4s 7ms/step - loss: 0.6143 - acc: 0.8928 - val_loss: 0.5982 - val_acc: 0.8967\n",
            "Epoch 2/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6125 - acc: 0.8976 - val_loss: 0.5962 - val_acc: 0.9005\n",
            "Epoch 3/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6107 - acc: 0.9025 - val_loss: 0.5943 - val_acc: 0.9043\n",
            "Epoch 4/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6089 - acc: 0.9070 - val_loss: 0.5924 - val_acc: 0.9073\n",
            "Epoch 5/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6071 - acc: 0.9115 - val_loss: 0.5906 - val_acc: 0.9105\n",
            "Epoch 6/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6053 - acc: 0.9161 - val_loss: 0.5887 - val_acc: 0.9136\n",
            "Epoch 7/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6035 - acc: 0.9204 - val_loss: 0.5869 - val_acc: 0.9166\n",
            "Epoch 8/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6017 - acc: 0.9249 - val_loss: 0.5850 - val_acc: 0.9197\n",
            "Epoch 9/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5999 - acc: 0.9291 - val_loss: 0.5832 - val_acc: 0.9233\n",
            "Epoch 10/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5981 - acc: 0.9334 - val_loss: 0.5814 - val_acc: 0.9268\n",
            "Epoch 11/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5963 - acc: 0.9378 - val_loss: 0.5796 - val_acc: 0.9303\n",
            "Epoch 12/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5945 - acc: 0.9418 - val_loss: 0.5777 - val_acc: 0.9341\n",
            "Epoch 13/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5928 - acc: 0.9458 - val_loss: 0.5759 - val_acc: 0.9371\n",
            "Epoch 14/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5910 - acc: 0.9498 - val_loss: 0.5741 - val_acc: 0.9405\n",
            "Epoch 15/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5892 - acc: 0.9534 - val_loss: 0.5723 - val_acc: 0.9442\n",
            "Epoch 16/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5875 - acc: 0.9570 - val_loss: 0.5705 - val_acc: 0.9480\n",
            "Epoch 17/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5857 - acc: 0.9604 - val_loss: 0.5687 - val_acc: 0.9516\n",
            "Epoch 18/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5840 - acc: 0.9634 - val_loss: 0.5669 - val_acc: 0.9551\n",
            "Epoch 19/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5822 - acc: 0.9664 - val_loss: 0.5652 - val_acc: 0.9587\n",
            "Epoch 20/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5805 - acc: 0.9692 - val_loss: 0.5634 - val_acc: 0.9621\n",
            "Epoch 21/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5788 - acc: 0.9718 - val_loss: 0.5616 - val_acc: 0.9661\n",
            "Epoch 22/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5770 - acc: 0.9742 - val_loss: 0.5598 - val_acc: 0.9694\n",
            "Epoch 23/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5753 - acc: 0.9763 - val_loss: 0.5581 - val_acc: 0.9728\n",
            "Epoch 24/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5736 - acc: 0.9781 - val_loss: 0.5563 - val_acc: 0.9758\n",
            "Epoch 25/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5718 - acc: 0.9798 - val_loss: 0.5546 - val_acc: 0.9786\n",
            "Epoch 26/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5701 - acc: 0.9813 - val_loss: 0.5528 - val_acc: 0.9810\n",
            "Epoch 27/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5684 - acc: 0.9829 - val_loss: 0.5511 - val_acc: 0.9837\n",
            "Epoch 28/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5667 - acc: 0.9841 - val_loss: 0.5493 - val_acc: 0.9858\n",
            "Epoch 29/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5650 - acc: 0.9852 - val_loss: 0.5476 - val_acc: 0.9878\n",
            "Epoch 30/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5633 - acc: 0.9862 - val_loss: 0.5458 - val_acc: 0.9895\n",
            "Epoch 31/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5616 - acc: 0.9870 - val_loss: 0.5441 - val_acc: 0.9910\n",
            "Epoch 32/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5599 - acc: 0.9876 - val_loss: 0.5424 - val_acc: 0.9922\n",
            "Epoch 33/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5582 - acc: 0.9881 - val_loss: 0.5406 - val_acc: 0.9929\n",
            "Epoch 34/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5565 - acc: 0.9886 - val_loss: 0.5389 - val_acc: 0.9934\n",
            "Epoch 35/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5548 - acc: 0.9891 - val_loss: 0.5372 - val_acc: 0.9937\n",
            "Epoch 36/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5532 - acc: 0.9895 - val_loss: 0.5355 - val_acc: 0.9937\n",
            "Epoch 37/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5515 - acc: 0.9899 - val_loss: 0.5338 - val_acc: 0.9937\n",
            "Epoch 38/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5498 - acc: 0.9902 - val_loss: 0.5321 - val_acc: 0.9937\n",
            "Epoch 39/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5481 - acc: 0.9905 - val_loss: 0.5304 - val_acc: 0.9937\n",
            "Epoch 40/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5465 - acc: 0.9907 - val_loss: 0.5287 - val_acc: 0.9937\n",
            "Epoch 41/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5448 - acc: 0.9910 - val_loss: 0.5270 - val_acc: 0.9937\n",
            "Epoch 42/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5431 - acc: 0.9912 - val_loss: 0.5253 - val_acc: 0.9937\n",
            "Epoch 43/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5415 - acc: 0.9914 - val_loss: 0.5236 - val_acc: 0.9937\n",
            "Epoch 44/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5398 - acc: 0.9916 - val_loss: 0.5219 - val_acc: 0.9937\n",
            "Epoch 45/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5382 - acc: 0.9917 - val_loss: 0.5202 - val_acc: 0.9937\n",
            "Epoch 46/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5365 - acc: 0.9918 - val_loss: 0.5185 - val_acc: 0.9937\n",
            "Epoch 47/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5349 - acc: 0.9919 - val_loss: 0.5169 - val_acc: 0.9937\n",
            "Epoch 48/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5332 - acc: 0.9920 - val_loss: 0.5152 - val_acc: 0.9937\n",
            "Epoch 49/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5316 - acc: 0.9921 - val_loss: 0.5135 - val_acc: 0.9937\n",
            "Epoch 50/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5300 - acc: 0.9921 - val_loss: 0.5119 - val_acc: 0.9937\n",
            "Epoch 51/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5283 - acc: 0.9921 - val_loss: 0.5102 - val_acc: 0.9937\n",
            "Epoch 52/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5267 - acc: 0.9921 - val_loss: 0.5085 - val_acc: 0.9937\n",
            "Epoch 53/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5251 - acc: 0.9922 - val_loss: 0.5069 - val_acc: 0.9937\n",
            "Epoch 54/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5235 - acc: 0.9922 - val_loss: 0.5052 - val_acc: 0.9937\n",
            "Epoch 55/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5219 - acc: 0.9922 - val_loss: 0.5036 - val_acc: 0.9937\n",
            "Epoch 56/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5202 - acc: 0.9922 - val_loss: 0.5019 - val_acc: 0.9937\n",
            "Epoch 57/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5186 - acc: 0.9922 - val_loss: 0.5003 - val_acc: 0.9937\n",
            "Epoch 58/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5170 - acc: 0.9922 - val_loss: 0.4986 - val_acc: 0.9937\n",
            "Epoch 59/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5154 - acc: 0.9922 - val_loss: 0.4970 - val_acc: 0.9937\n",
            "Epoch 60/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5138 - acc: 0.9922 - val_loss: 0.4954 - val_acc: 0.9937\n",
            "Epoch 61/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5122 - acc: 0.9922 - val_loss: 0.4937 - val_acc: 0.9937\n",
            "Epoch 62/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5106 - acc: 0.9922 - val_loss: 0.4921 - val_acc: 0.9937\n",
            "Epoch 63/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5090 - acc: 0.9922 - val_loss: 0.4905 - val_acc: 0.9937\n",
            "Epoch 64/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5074 - acc: 0.9922 - val_loss: 0.4889 - val_acc: 0.9937\n",
            "Epoch 65/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5058 - acc: 0.9922 - val_loss: 0.4873 - val_acc: 0.9937\n",
            "Epoch 66/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5043 - acc: 0.9922 - val_loss: 0.4856 - val_acc: 0.9937\n",
            "Epoch 67/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5027 - acc: 0.9922 - val_loss: 0.4840 - val_acc: 0.9937\n",
            "Epoch 68/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5011 - acc: 0.9922 - val_loss: 0.4824 - val_acc: 0.9937\n",
            "Epoch 69/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4995 - acc: 0.9922 - val_loss: 0.4808 - val_acc: 0.9937\n",
            "Epoch 70/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4980 - acc: 0.9922 - val_loss: 0.4792 - val_acc: 0.9937\n",
            "Epoch 71/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4964 - acc: 0.9922 - val_loss: 0.4776 - val_acc: 0.9937\n",
            "Epoch 72/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4948 - acc: 0.9922 - val_loss: 0.4760 - val_acc: 0.9937\n",
            "Epoch 73/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4933 - acc: 0.9922 - val_loss: 0.4744 - val_acc: 0.9937\n",
            "Epoch 74/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4917 - acc: 0.9922 - val_loss: 0.4728 - val_acc: 0.9937\n",
            "Epoch 75/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4901 - acc: 0.9922 - val_loss: 0.4713 - val_acc: 0.9937\n",
            "Epoch 76/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4886 - acc: 0.9922 - val_loss: 0.4697 - val_acc: 0.9937\n",
            "Epoch 77/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4870 - acc: 0.9922 - val_loss: 0.4681 - val_acc: 0.9937\n",
            "Epoch 78/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4855 - acc: 0.9922 - val_loss: 0.4665 - val_acc: 0.9937\n",
            "Epoch 79/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4839 - acc: 0.9922 - val_loss: 0.4649 - val_acc: 0.9937\n",
            "Epoch 80/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4824 - acc: 0.9922 - val_loss: 0.4634 - val_acc: 0.9937\n",
            "Epoch 81/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4809 - acc: 0.9922 - val_loss: 0.4618 - val_acc: 0.9937\n",
            "Epoch 82/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4793 - acc: 0.9922 - val_loss: 0.4602 - val_acc: 0.9937\n",
            "Epoch 83/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4778 - acc: 0.9922 - val_loss: 0.4587 - val_acc: 0.9937\n",
            "Epoch 84/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4763 - acc: 0.9922 - val_loss: 0.4571 - val_acc: 0.9937\n",
            "Epoch 85/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4747 - acc: 0.9922 - val_loss: 0.4556 - val_acc: 0.9937\n",
            "Epoch 86/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4732 - acc: 0.9922 - val_loss: 0.4540 - val_acc: 0.9937\n",
            "Epoch 87/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4717 - acc: 0.9922 - val_loss: 0.4525 - val_acc: 0.9937\n",
            "Epoch 88/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4702 - acc: 0.9922 - val_loss: 0.4509 - val_acc: 0.9937\n",
            "Epoch 89/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4687 - acc: 0.9922 - val_loss: 0.4494 - val_acc: 0.9937\n",
            "Epoch 90/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4671 - acc: 0.9922 - val_loss: 0.4479 - val_acc: 0.9937\n",
            "Epoch 91/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4656 - acc: 0.9922 - val_loss: 0.4463 - val_acc: 0.9937\n",
            "Epoch 92/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4641 - acc: 0.9922 - val_loss: 0.4448 - val_acc: 0.9937\n",
            "Epoch 93/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4626 - acc: 0.9922 - val_loss: 0.4433 - val_acc: 0.9937\n",
            "Epoch 94/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4611 - acc: 0.9922 - val_loss: 0.4417 - val_acc: 0.9937\n",
            "Epoch 95/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4596 - acc: 0.9922 - val_loss: 0.4402 - val_acc: 0.9937\n",
            "Epoch 96/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4581 - acc: 0.9922 - val_loss: 0.4387 - val_acc: 0.9937\n",
            "Epoch 97/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4567 - acc: 0.9922 - val_loss: 0.4372 - val_acc: 0.9937\n",
            "Epoch 98/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4552 - acc: 0.9922 - val_loss: 0.4357 - val_acc: 0.9937\n",
            "Epoch 99/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4537 - acc: 0.9922 - val_loss: 0.4342 - val_acc: 0.9937\n",
            "Epoch 100/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4522 - acc: 0.9922 - val_loss: 0.4327 - val_acc: 0.9937\n",
            "Epoch 101/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4507 - acc: 0.9922 - val_loss: 0.4312 - val_acc: 0.9937\n",
            "Epoch 102/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4493 - acc: 0.9922 - val_loss: 0.4297 - val_acc: 0.9937\n",
            "Epoch 103/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4478 - acc: 0.9922 - val_loss: 0.4282 - val_acc: 0.9937\n",
            "Epoch 104/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4463 - acc: 0.9922 - val_loss: 0.4267 - val_acc: 0.9937\n",
            "Epoch 105/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4448 - acc: 0.9922 - val_loss: 0.4252 - val_acc: 0.9937\n",
            "Epoch 106/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4434 - acc: 0.9922 - val_loss: 0.4237 - val_acc: 0.9937\n",
            "Epoch 107/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4419 - acc: 0.9922 - val_loss: 0.4222 - val_acc: 0.9937\n",
            "Epoch 108/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4405 - acc: 0.9922 - val_loss: 0.4208 - val_acc: 0.9937\n",
            "Epoch 109/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4390 - acc: 0.9922 - val_loss: 0.4193 - val_acc: 0.9937\n",
            "Epoch 110/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4376 - acc: 0.9922 - val_loss: 0.4178 - val_acc: 0.9937\n",
            "Epoch 111/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4361 - acc: 0.9922 - val_loss: 0.4163 - val_acc: 0.9937\n",
            "Epoch 112/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4347 - acc: 0.9922 - val_loss: 0.4149 - val_acc: 0.9937\n",
            "Epoch 113/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4332 - acc: 0.9922 - val_loss: 0.4134 - val_acc: 0.9937\n",
            "Epoch 114/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4318 - acc: 0.9922 - val_loss: 0.4120 - val_acc: 0.9937\n",
            "Epoch 115/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4304 - acc: 0.9922 - val_loss: 0.4105 - val_acc: 0.9937\n",
            "Epoch 116/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4290 - acc: 0.9922 - val_loss: 0.4091 - val_acc: 0.9937\n",
            "Epoch 117/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4275 - acc: 0.9922 - val_loss: 0.4076 - val_acc: 0.9937\n",
            "Epoch 118/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4261 - acc: 0.9922 - val_loss: 0.4062 - val_acc: 0.9937\n",
            "Epoch 119/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4247 - acc: 0.9922 - val_loss: 0.4047 - val_acc: 0.9937\n",
            "Epoch 120/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4233 - acc: 0.9922 - val_loss: 0.4033 - val_acc: 0.9937\n",
            "Epoch 121/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4219 - acc: 0.9922 - val_loss: 0.4019 - val_acc: 0.9937\n",
            "Epoch 122/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4205 - acc: 0.9922 - val_loss: 0.4004 - val_acc: 0.9937\n",
            "Epoch 123/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4191 - acc: 0.9922 - val_loss: 0.3990 - val_acc: 0.9937\n",
            "Epoch 124/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4176 - acc: 0.9922 - val_loss: 0.3976 - val_acc: 0.9937\n",
            "Epoch 125/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4163 - acc: 0.9922 - val_loss: 0.3962 - val_acc: 0.9937\n",
            "Epoch 126/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4149 - acc: 0.9922 - val_loss: 0.3948 - val_acc: 0.9937\n",
            "Epoch 127/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4135 - acc: 0.9922 - val_loss: 0.3933 - val_acc: 0.9937\n",
            "Epoch 128/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4121 - acc: 0.9922 - val_loss: 0.3919 - val_acc: 0.9937\n",
            "Epoch 129/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4107 - acc: 0.9922 - val_loss: 0.3905 - val_acc: 0.9937\n",
            "Epoch 130/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4093 - acc: 0.9922 - val_loss: 0.3891 - val_acc: 0.9937\n",
            "Epoch 131/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4079 - acc: 0.9922 - val_loss: 0.3877 - val_acc: 0.9937\n",
            "Epoch 132/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4066 - acc: 0.9922 - val_loss: 0.3863 - val_acc: 0.9937\n",
            "Epoch 133/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4052 - acc: 0.9922 - val_loss: 0.3849 - val_acc: 0.9937\n",
            "Epoch 134/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4038 - acc: 0.9922 - val_loss: 0.3836 - val_acc: 0.9937\n",
            "Epoch 135/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4025 - acc: 0.9922 - val_loss: 0.3822 - val_acc: 0.9937\n",
            "Epoch 136/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4011 - acc: 0.9922 - val_loss: 0.3808 - val_acc: 0.9937\n",
            "Epoch 137/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3997 - acc: 0.9922 - val_loss: 0.3794 - val_acc: 0.9937\n",
            "Epoch 138/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3984 - acc: 0.9922 - val_loss: 0.3780 - val_acc: 0.9937\n",
            "Epoch 139/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3970 - acc: 0.9922 - val_loss: 0.3767 - val_acc: 0.9937\n",
            "Epoch 140/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3957 - acc: 0.9922 - val_loss: 0.3753 - val_acc: 0.9937\n",
            "Epoch 141/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3943 - acc: 0.9922 - val_loss: 0.3739 - val_acc: 0.9937\n",
            "Epoch 142/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3930 - acc: 0.9922 - val_loss: 0.3726 - val_acc: 0.9937\n",
            "Epoch 143/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3917 - acc: 0.9922 - val_loss: 0.3712 - val_acc: 0.9937\n",
            "Epoch 144/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3903 - acc: 0.9922 - val_loss: 0.3698 - val_acc: 0.9937\n",
            "Epoch 145/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3890 - acc: 0.9922 - val_loss: 0.3685 - val_acc: 0.9937\n",
            "Epoch 146/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3877 - acc: 0.9922 - val_loss: 0.3671 - val_acc: 0.9937\n",
            "Epoch 147/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3863 - acc: 0.9922 - val_loss: 0.3658 - val_acc: 0.9937\n",
            "Epoch 148/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3850 - acc: 0.9922 - val_loss: 0.3645 - val_acc: 0.9937\n",
            "Epoch 149/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3837 - acc: 0.9922 - val_loss: 0.3631 - val_acc: 0.9937\n",
            "Epoch 150/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3824 - acc: 0.9922 - val_loss: 0.3618 - val_acc: 0.9937\n",
            "Epoch 151/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3811 - acc: 0.9922 - val_loss: 0.3605 - val_acc: 0.9937\n",
            "Epoch 152/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3798 - acc: 0.9922 - val_loss: 0.3591 - val_acc: 0.9937\n",
            "Epoch 153/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3785 - acc: 0.9922 - val_loss: 0.3578 - val_acc: 0.9937\n",
            "Epoch 154/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3772 - acc: 0.9922 - val_loss: 0.3565 - val_acc: 0.9937\n",
            "Epoch 155/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3759 - acc: 0.9922 - val_loss: 0.3552 - val_acc: 0.9937\n",
            "Epoch 156/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3746 - acc: 0.9922 - val_loss: 0.3539 - val_acc: 0.9937\n",
            "Epoch 157/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3733 - acc: 0.9922 - val_loss: 0.3525 - val_acc: 0.9937\n",
            "Epoch 158/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3720 - acc: 0.9922 - val_loss: 0.3512 - val_acc: 0.9937\n",
            "Epoch 159/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3707 - acc: 0.9922 - val_loss: 0.3499 - val_acc: 0.9937\n",
            "Epoch 160/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3694 - acc: 0.9922 - val_loss: 0.3486 - val_acc: 0.9937\n",
            "Epoch 161/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3682 - acc: 0.9922 - val_loss: 0.3473 - val_acc: 0.9937\n",
            "Epoch 162/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3669 - acc: 0.9922 - val_loss: 0.3460 - val_acc: 0.9937\n",
            "Epoch 163/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3656 - acc: 0.9922 - val_loss: 0.3448 - val_acc: 0.9937\n",
            "Epoch 164/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3643 - acc: 0.9922 - val_loss: 0.3435 - val_acc: 0.9937\n",
            "Epoch 165/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3631 - acc: 0.9922 - val_loss: 0.3422 - val_acc: 0.9937\n",
            "Epoch 166/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3618 - acc: 0.9922 - val_loss: 0.3409 - val_acc: 0.9937\n",
            "Epoch 167/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3606 - acc: 0.9922 - val_loss: 0.3396 - val_acc: 0.9937\n",
            "Epoch 168/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3593 - acc: 0.9922 - val_loss: 0.3384 - val_acc: 0.9937\n",
            "Epoch 169/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3581 - acc: 0.9922 - val_loss: 0.3371 - val_acc: 0.9937\n",
            "Epoch 170/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3568 - acc: 0.9922 - val_loss: 0.3358 - val_acc: 0.9937\n",
            "Epoch 171/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3556 - acc: 0.9922 - val_loss: 0.3346 - val_acc: 0.9937\n",
            "Epoch 172/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3543 - acc: 0.9922 - val_loss: 0.3333 - val_acc: 0.9937\n",
            "Epoch 173/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3531 - acc: 0.9922 - val_loss: 0.3320 - val_acc: 0.9937\n",
            "Epoch 174/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3519 - acc: 0.9922 - val_loss: 0.3308 - val_acc: 0.9937\n",
            "Epoch 175/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3507 - acc: 0.9922 - val_loss: 0.3295 - val_acc: 0.9937\n",
            "Epoch 176/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3494 - acc: 0.9922 - val_loss: 0.3283 - val_acc: 0.9937\n",
            "Epoch 177/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3482 - acc: 0.9922 - val_loss: 0.3270 - val_acc: 0.9937\n",
            "Epoch 178/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3470 - acc: 0.9922 - val_loss: 0.3258 - val_acc: 0.9937\n",
            "Epoch 179/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3458 - acc: 0.9922 - val_loss: 0.3246 - val_acc: 0.9937\n",
            "Epoch 180/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3446 - acc: 0.9922 - val_loss: 0.3233 - val_acc: 0.9937\n",
            "Epoch 181/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3434 - acc: 0.9922 - val_loss: 0.3221 - val_acc: 0.9937\n",
            "Epoch 182/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3422 - acc: 0.9922 - val_loss: 0.3209 - val_acc: 0.9937\n",
            "Epoch 183/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3410 - acc: 0.9922 - val_loss: 0.3197 - val_acc: 0.9937\n",
            "Epoch 184/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3398 - acc: 0.9922 - val_loss: 0.3184 - val_acc: 0.9937\n",
            "Epoch 185/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3386 - acc: 0.9922 - val_loss: 0.3172 - val_acc: 0.9937\n",
            "Epoch 186/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3374 - acc: 0.9922 - val_loss: 0.3160 - val_acc: 0.9937\n",
            "Epoch 187/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3362 - acc: 0.9922 - val_loss: 0.3148 - val_acc: 0.9937\n",
            "Epoch 188/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3350 - acc: 0.9922 - val_loss: 0.3136 - val_acc: 0.9937\n",
            "Epoch 189/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3338 - acc: 0.9922 - val_loss: 0.3124 - val_acc: 0.9937\n",
            "Epoch 190/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3327 - acc: 0.9922 - val_loss: 0.3112 - val_acc: 0.9937\n",
            "Epoch 191/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3315 - acc: 0.9922 - val_loss: 0.3100 - val_acc: 0.9937\n",
            "Epoch 192/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3303 - acc: 0.9922 - val_loss: 0.3088 - val_acc: 0.9937\n",
            "Epoch 193/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3291 - acc: 0.9922 - val_loss: 0.3076 - val_acc: 0.9937\n",
            "Epoch 194/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3280 - acc: 0.9922 - val_loss: 0.3064 - val_acc: 0.9937\n",
            "Epoch 195/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3268 - acc: 0.9922 - val_loss: 0.3053 - val_acc: 0.9937\n",
            "Epoch 196/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3257 - acc: 0.9922 - val_loss: 0.3041 - val_acc: 0.9937\n",
            "Epoch 197/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3245 - acc: 0.9922 - val_loss: 0.3029 - val_acc: 0.9937\n",
            "Epoch 198/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3234 - acc: 0.9922 - val_loss: 0.3017 - val_acc: 0.9937\n",
            "Epoch 199/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3222 - acc: 0.9922 - val_loss: 0.3006 - val_acc: 0.9937\n",
            "Epoch 200/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3211 - acc: 0.9922 - val_loss: 0.2994 - val_acc: 0.9937\n",
            "Epoch 201/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3199 - acc: 0.9922 - val_loss: 0.2982 - val_acc: 0.9937\n",
            "Epoch 202/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3188 - acc: 0.9922 - val_loss: 0.2971 - val_acc: 0.9937\n",
            "Epoch 203/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3177 - acc: 0.9922 - val_loss: 0.2959 - val_acc: 0.9937\n",
            "Epoch 204/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3165 - acc: 0.9922 - val_loss: 0.2948 - val_acc: 0.9937\n",
            "Epoch 205/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3154 - acc: 0.9922 - val_loss: 0.2936 - val_acc: 0.9937\n",
            "Epoch 206/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3143 - acc: 0.9922 - val_loss: 0.2925 - val_acc: 0.9937\n",
            "Epoch 207/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3132 - acc: 0.9922 - val_loss: 0.2914 - val_acc: 0.9937\n",
            "Epoch 208/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3121 - acc: 0.9922 - val_loss: 0.2902 - val_acc: 0.9937\n",
            "Epoch 209/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3109 - acc: 0.9922 - val_loss: 0.2891 - val_acc: 0.9937\n",
            "Epoch 210/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3098 - acc: 0.9922 - val_loss: 0.2880 - val_acc: 0.9937\n",
            "Epoch 211/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3087 - acc: 0.9922 - val_loss: 0.2868 - val_acc: 0.9937\n",
            "Epoch 212/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3076 - acc: 0.9922 - val_loss: 0.2857 - val_acc: 0.9937\n",
            "Epoch 213/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3065 - acc: 0.9922 - val_loss: 0.2846 - val_acc: 0.9937\n",
            "Epoch 214/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3054 - acc: 0.9922 - val_loss: 0.2835 - val_acc: 0.9937\n",
            "Epoch 215/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3043 - acc: 0.9922 - val_loss: 0.2824 - val_acc: 0.9937\n",
            "Epoch 216/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3033 - acc: 0.9922 - val_loss: 0.2812 - val_acc: 0.9937\n",
            "Epoch 217/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3022 - acc: 0.9922 - val_loss: 0.2801 - val_acc: 0.9937\n",
            "Epoch 218/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3011 - acc: 0.9922 - val_loss: 0.2790 - val_acc: 0.9937\n",
            "Epoch 219/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3000 - acc: 0.9922 - val_loss: 0.2779 - val_acc: 0.9937\n",
            "Epoch 220/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2989 - acc: 0.9922 - val_loss: 0.2768 - val_acc: 0.9937\n",
            "Epoch 221/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2979 - acc: 0.9922 - val_loss: 0.2757 - val_acc: 0.9937\n",
            "Epoch 222/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2968 - acc: 0.9922 - val_loss: 0.2747 - val_acc: 0.9937\n",
            "Epoch 223/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2957 - acc: 0.9922 - val_loss: 0.2736 - val_acc: 0.9937\n",
            "Epoch 224/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2947 - acc: 0.9922 - val_loss: 0.2725 - val_acc: 0.9937\n",
            "Epoch 225/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2936 - acc: 0.9922 - val_loss: 0.2714 - val_acc: 0.9937\n",
            "Epoch 226/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2925 - acc: 0.9922 - val_loss: 0.2703 - val_acc: 0.9937\n",
            "Epoch 227/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2915 - acc: 0.9922 - val_loss: 0.2693 - val_acc: 0.9937\n",
            "Epoch 228/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2904 - acc: 0.9922 - val_loss: 0.2682 - val_acc: 0.9937\n",
            "Epoch 229/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2894 - acc: 0.9922 - val_loss: 0.2671 - val_acc: 0.9937\n",
            "Epoch 230/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2883 - acc: 0.9922 - val_loss: 0.2661 - val_acc: 0.9937\n",
            "Epoch 231/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2873 - acc: 0.9922 - val_loss: 0.2650 - val_acc: 0.9937\n",
            "Epoch 232/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2863 - acc: 0.9922 - val_loss: 0.2639 - val_acc: 0.9937\n",
            "Epoch 233/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2852 - acc: 0.9922 - val_loss: 0.2629 - val_acc: 0.9937\n",
            "Epoch 234/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2842 - acc: 0.9922 - val_loss: 0.2618 - val_acc: 0.9937\n",
            "Epoch 235/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2832 - acc: 0.9922 - val_loss: 0.2608 - val_acc: 0.9937\n",
            "Epoch 236/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2822 - acc: 0.9922 - val_loss: 0.2598 - val_acc: 0.9937\n",
            "Epoch 237/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2811 - acc: 0.9922 - val_loss: 0.2587 - val_acc: 0.9937\n",
            "Epoch 238/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2801 - acc: 0.9922 - val_loss: 0.2577 - val_acc: 0.9937\n",
            "Epoch 239/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2791 - acc: 0.9922 - val_loss: 0.2567 - val_acc: 0.9937\n",
            "Epoch 240/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2781 - acc: 0.9922 - val_loss: 0.2556 - val_acc: 0.9937\n",
            "Epoch 241/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2771 - acc: 0.9922 - val_loss: 0.2546 - val_acc: 0.9937\n",
            "Epoch 242/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2761 - acc: 0.9922 - val_loss: 0.2536 - val_acc: 0.9937\n",
            "Epoch 243/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2751 - acc: 0.9922 - val_loss: 0.2526 - val_acc: 0.9937\n",
            "Epoch 244/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2741 - acc: 0.9922 - val_loss: 0.2515 - val_acc: 0.9937\n",
            "Epoch 245/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2731 - acc: 0.9922 - val_loss: 0.2505 - val_acc: 0.9937\n",
            "Epoch 246/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2721 - acc: 0.9922 - val_loss: 0.2495 - val_acc: 0.9937\n",
            "Epoch 247/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2711 - acc: 0.9922 - val_loss: 0.2485 - val_acc: 0.9937\n",
            "Epoch 248/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2701 - acc: 0.9922 - val_loss: 0.2475 - val_acc: 0.9937\n",
            "Epoch 249/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2691 - acc: 0.9922 - val_loss: 0.2465 - val_acc: 0.9937\n",
            "Epoch 250/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2681 - acc: 0.9922 - val_loss: 0.2455 - val_acc: 0.9937\n",
            "Epoch 251/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2672 - acc: 0.9922 - val_loss: 0.2445 - val_acc: 0.9937\n",
            "Epoch 252/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2662 - acc: 0.9922 - val_loss: 0.2435 - val_acc: 0.9937\n",
            "Epoch 253/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2652 - acc: 0.9922 - val_loss: 0.2426 - val_acc: 0.9937\n",
            "Epoch 254/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2643 - acc: 0.9922 - val_loss: 0.2416 - val_acc: 0.9937\n",
            "Epoch 255/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2633 - acc: 0.9922 - val_loss: 0.2406 - val_acc: 0.9937\n",
            "Epoch 256/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2623 - acc: 0.9922 - val_loss: 0.2396 - val_acc: 0.9937\n",
            "Epoch 257/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2614 - acc: 0.9922 - val_loss: 0.2387 - val_acc: 0.9937\n",
            "Epoch 258/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2604 - acc: 0.9922 - val_loss: 0.2377 - val_acc: 0.9937\n",
            "Epoch 259/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2595 - acc: 0.9922 - val_loss: 0.2367 - val_acc: 0.9937\n",
            "Epoch 260/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2585 - acc: 0.9922 - val_loss: 0.2358 - val_acc: 0.9937\n",
            "Epoch 261/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2576 - acc: 0.9922 - val_loss: 0.2348 - val_acc: 0.9937\n",
            "Epoch 262/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2566 - acc: 0.9922 - val_loss: 0.2339 - val_acc: 0.9937\n",
            "Epoch 263/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2557 - acc: 0.9922 - val_loss: 0.2329 - val_acc: 0.9937\n",
            "Epoch 264/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2547 - acc: 0.9922 - val_loss: 0.2320 - val_acc: 0.9937\n",
            "Epoch 265/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2538 - acc: 0.9922 - val_loss: 0.2310 - val_acc: 0.9937\n",
            "Epoch 266/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2529 - acc: 0.9922 - val_loss: 0.2301 - val_acc: 0.9937\n",
            "Epoch 267/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2520 - acc: 0.9922 - val_loss: 0.2291 - val_acc: 0.9937\n",
            "Epoch 268/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2510 - acc: 0.9922 - val_loss: 0.2282 - val_acc: 0.9937\n",
            "Epoch 269/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2501 - acc: 0.9922 - val_loss: 0.2273 - val_acc: 0.9937\n",
            "Epoch 270/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2492 - acc: 0.9922 - val_loss: 0.2264 - val_acc: 0.9937\n",
            "Epoch 271/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2483 - acc: 0.9922 - val_loss: 0.2254 - val_acc: 0.9937\n",
            "Epoch 272/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2474 - acc: 0.9922 - val_loss: 0.2245 - val_acc: 0.9937\n",
            "Epoch 273/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2465 - acc: 0.9922 - val_loss: 0.2236 - val_acc: 0.9937\n",
            "Epoch 274/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2456 - acc: 0.9922 - val_loss: 0.2227 - val_acc: 0.9937\n",
            "Epoch 275/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2447 - acc: 0.9922 - val_loss: 0.2218 - val_acc: 0.9937\n",
            "Epoch 276/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2438 - acc: 0.9922 - val_loss: 0.2209 - val_acc: 0.9937\n",
            "Epoch 277/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2429 - acc: 0.9922 - val_loss: 0.2200 - val_acc: 0.9937\n",
            "Epoch 278/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2420 - acc: 0.9922 - val_loss: 0.2191 - val_acc: 0.9937\n",
            "Epoch 279/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2411 - acc: 0.9922 - val_loss: 0.2182 - val_acc: 0.9937\n",
            "Epoch 280/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2402 - acc: 0.9922 - val_loss: 0.2173 - val_acc: 0.9937\n",
            "Epoch 281/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2393 - acc: 0.9922 - val_loss: 0.2164 - val_acc: 0.9937\n",
            "Epoch 282/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2384 - acc: 0.9922 - val_loss: 0.2155 - val_acc: 0.9937\n",
            "Epoch 283/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2375 - acc: 0.9922 - val_loss: 0.2146 - val_acc: 0.9937\n",
            "Epoch 284/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2367 - acc: 0.9922 - val_loss: 0.2137 - val_acc: 0.9937\n",
            "Epoch 285/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2358 - acc: 0.9922 - val_loss: 0.2129 - val_acc: 0.9937\n",
            "Epoch 286/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2349 - acc: 0.9922 - val_loss: 0.2120 - val_acc: 0.9937\n",
            "Epoch 287/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2341 - acc: 0.9922 - val_loss: 0.2111 - val_acc: 0.9937\n",
            "Epoch 288/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2332 - acc: 0.9922 - val_loss: 0.2103 - val_acc: 0.9937\n",
            "Epoch 289/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2324 - acc: 0.9922 - val_loss: 0.2094 - val_acc: 0.9937\n",
            "Epoch 290/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2315 - acc: 0.9922 - val_loss: 0.2085 - val_acc: 0.9937\n",
            "Epoch 291/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2306 - acc: 0.9922 - val_loss: 0.2077 - val_acc: 0.9937\n",
            "Epoch 292/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2298 - acc: 0.9922 - val_loss: 0.2068 - val_acc: 0.9937\n",
            "Epoch 293/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2289 - acc: 0.9922 - val_loss: 0.2060 - val_acc: 0.9937\n",
            "Epoch 294/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2281 - acc: 0.9922 - val_loss: 0.2051 - val_acc: 0.9937\n",
            "Epoch 295/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2273 - acc: 0.9922 - val_loss: 0.2043 - val_acc: 0.9937\n",
            "Epoch 296/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2264 - acc: 0.9922 - val_loss: 0.2035 - val_acc: 0.9937\n",
            "Epoch 297/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2256 - acc: 0.9922 - val_loss: 0.2026 - val_acc: 0.9937\n",
            "Epoch 298/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2248 - acc: 0.9922 - val_loss: 0.2018 - val_acc: 0.9937\n",
            "Epoch 299/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2239 - acc: 0.9922 - val_loss: 0.2010 - val_acc: 0.9937\n",
            "Epoch 300/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2231 - acc: 0.9922 - val_loss: 0.2001 - val_acc: 0.9937\n",
            "Epoch 301/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2223 - acc: 0.9922 - val_loss: 0.1993 - val_acc: 0.9937\n",
            "Epoch 302/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2215 - acc: 0.9922 - val_loss: 0.1985 - val_acc: 0.9937\n",
            "Epoch 303/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.2207 - acc: 0.9922 - val_loss: 0.1977 - val_acc: 0.9937\n",
            "Epoch 304/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2198 - acc: 0.9922 - val_loss: 0.1969 - val_acc: 0.9937\n",
            "Epoch 305/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2190 - acc: 0.9922 - val_loss: 0.1961 - val_acc: 0.9937\n",
            "Epoch 306/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2182 - acc: 0.9922 - val_loss: 0.1953 - val_acc: 0.9937\n",
            "Epoch 307/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2174 - acc: 0.9922 - val_loss: 0.1945 - val_acc: 0.9937\n",
            "Epoch 308/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2166 - acc: 0.9922 - val_loss: 0.1937 - val_acc: 0.9937\n",
            "Epoch 309/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2158 - acc: 0.9922 - val_loss: 0.1929 - val_acc: 0.9937\n",
            "Epoch 310/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2150 - acc: 0.9922 - val_loss: 0.1921 - val_acc: 0.9937\n",
            "Epoch 311/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2142 - acc: 0.9922 - val_loss: 0.1913 - val_acc: 0.9937\n",
            "Epoch 312/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2134 - acc: 0.9922 - val_loss: 0.1905 - val_acc: 0.9937\n",
            "Epoch 313/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2127 - acc: 0.9922 - val_loss: 0.1897 - val_acc: 0.9937\n",
            "Epoch 314/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2119 - acc: 0.9922 - val_loss: 0.1889 - val_acc: 0.9937\n",
            "Epoch 315/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2111 - acc: 0.9922 - val_loss: 0.1882 - val_acc: 0.9937\n",
            "Epoch 316/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2103 - acc: 0.9922 - val_loss: 0.1874 - val_acc: 0.9937\n",
            "Epoch 317/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2095 - acc: 0.9922 - val_loss: 0.1866 - val_acc: 0.9937\n",
            "Epoch 318/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2088 - acc: 0.9922 - val_loss: 0.1859 - val_acc: 0.9937\n",
            "Epoch 319/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2080 - acc: 0.9922 - val_loss: 0.1851 - val_acc: 0.9937\n",
            "Epoch 320/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2072 - acc: 0.9922 - val_loss: 0.1843 - val_acc: 0.9937\n",
            "Epoch 321/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2065 - acc: 0.9922 - val_loss: 0.1836 - val_acc: 0.9937\n",
            "Epoch 322/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2057 - acc: 0.9922 - val_loss: 0.1828 - val_acc: 0.9937\n",
            "Epoch 323/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2050 - acc: 0.9922 - val_loss: 0.1821 - val_acc: 0.9937\n",
            "Epoch 324/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2042 - acc: 0.9922 - val_loss: 0.1813 - val_acc: 0.9937\n",
            "Epoch 325/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2034 - acc: 0.9922 - val_loss: 0.1806 - val_acc: 0.9937\n",
            "Epoch 326/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2027 - acc: 0.9922 - val_loss: 0.1798 - val_acc: 0.9937\n",
            "Epoch 327/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2020 - acc: 0.9922 - val_loss: 0.1791 - val_acc: 0.9937\n",
            "Epoch 328/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2012 - acc: 0.9922 - val_loss: 0.1784 - val_acc: 0.9937\n",
            "Epoch 329/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2005 - acc: 0.9922 - val_loss: 0.1776 - val_acc: 0.9937\n",
            "Epoch 330/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1997 - acc: 0.9922 - val_loss: 0.1769 - val_acc: 0.9937\n",
            "Epoch 331/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1990 - acc: 0.9922 - val_loss: 0.1762 - val_acc: 0.9937\n",
            "Epoch 332/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1983 - acc: 0.9922 - val_loss: 0.1754 - val_acc: 0.9937\n",
            "Epoch 333/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1975 - acc: 0.9922 - val_loss: 0.1747 - val_acc: 0.9937\n",
            "Epoch 334/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1968 - acc: 0.9922 - val_loss: 0.1740 - val_acc: 0.9937\n",
            "Epoch 335/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1961 - acc: 0.9922 - val_loss: 0.1733 - val_acc: 0.9937\n",
            "Epoch 336/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1954 - acc: 0.9922 - val_loss: 0.1726 - val_acc: 0.9937\n",
            "Epoch 337/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1947 - acc: 0.9922 - val_loss: 0.1719 - val_acc: 0.9937\n",
            "Epoch 338/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1939 - acc: 0.9922 - val_loss: 0.1712 - val_acc: 0.9937\n",
            "Epoch 339/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1932 - acc: 0.9922 - val_loss: 0.1705 - val_acc: 0.9937\n",
            "Epoch 340/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1925 - acc: 0.9922 - val_loss: 0.1698 - val_acc: 0.9937\n",
            "Epoch 341/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1918 - acc: 0.9922 - val_loss: 0.1691 - val_acc: 0.9937\n",
            "Epoch 342/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1911 - acc: 0.9922 - val_loss: 0.1684 - val_acc: 0.9937\n",
            "Epoch 343/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1904 - acc: 0.9922 - val_loss: 0.1677 - val_acc: 0.9937\n",
            "Epoch 344/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1897 - acc: 0.9922 - val_loss: 0.1670 - val_acc: 0.9937\n",
            "Epoch 345/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1890 - acc: 0.9922 - val_loss: 0.1663 - val_acc: 0.9937\n",
            "Epoch 346/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1883 - acc: 0.9922 - val_loss: 0.1656 - val_acc: 0.9937\n",
            "Epoch 347/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1876 - acc: 0.9922 - val_loss: 0.1650 - val_acc: 0.9937\n",
            "Epoch 348/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1869 - acc: 0.9922 - val_loss: 0.1643 - val_acc: 0.9937\n",
            "Epoch 349/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1863 - acc: 0.9922 - val_loss: 0.1636 - val_acc: 0.9937\n",
            "Epoch 350/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1856 - acc: 0.9922 - val_loss: 0.1629 - val_acc: 0.9937\n",
            "Epoch 351/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1849 - acc: 0.9922 - val_loss: 0.1623 - val_acc: 0.9937\n",
            "Epoch 352/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1842 - acc: 0.9922 - val_loss: 0.1616 - val_acc: 0.9937\n",
            "Epoch 353/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1836 - acc: 0.9922 - val_loss: 0.1610 - val_acc: 0.9937\n",
            "Epoch 354/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1829 - acc: 0.9922 - val_loss: 0.1603 - val_acc: 0.9937\n",
            "Epoch 355/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1822 - acc: 0.9922 - val_loss: 0.1596 - val_acc: 0.9937\n",
            "Epoch 356/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1815 - acc: 0.9922 - val_loss: 0.1590 - val_acc: 0.9937\n",
            "Epoch 357/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1809 - acc: 0.9922 - val_loss: 0.1583 - val_acc: 0.9937\n",
            "Epoch 358/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1802 - acc: 0.9922 - val_loss: 0.1577 - val_acc: 0.9937\n",
            "Epoch 359/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1796 - acc: 0.9922 - val_loss: 0.1571 - val_acc: 0.9937\n",
            "Epoch 360/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1789 - acc: 0.9922 - val_loss: 0.1564 - val_acc: 0.9937\n",
            "Epoch 361/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1783 - acc: 0.9922 - val_loss: 0.1558 - val_acc: 0.9937\n",
            "Epoch 362/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1776 - acc: 0.9922 - val_loss: 0.1552 - val_acc: 0.9937\n",
            "Epoch 363/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1770 - acc: 0.9922 - val_loss: 0.1545 - val_acc: 0.9937\n",
            "Epoch 364/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1763 - acc: 0.9922 - val_loss: 0.1539 - val_acc: 0.9937\n",
            "Epoch 365/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1757 - acc: 0.9922 - val_loss: 0.1533 - val_acc: 0.9937\n",
            "Epoch 366/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1750 - acc: 0.9922 - val_loss: 0.1526 - val_acc: 0.9937\n",
            "Epoch 367/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1744 - acc: 0.9922 - val_loss: 0.1520 - val_acc: 0.9937\n",
            "Epoch 368/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1738 - acc: 0.9922 - val_loss: 0.1514 - val_acc: 0.9937\n",
            "Epoch 369/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1731 - acc: 0.9922 - val_loss: 0.1508 - val_acc: 0.9937\n",
            "Epoch 370/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1725 - acc: 0.9922 - val_loss: 0.1502 - val_acc: 0.9937\n",
            "Epoch 371/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1719 - acc: 0.9922 - val_loss: 0.1496 - val_acc: 0.9937\n",
            "Epoch 372/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1713 - acc: 0.9922 - val_loss: 0.1490 - val_acc: 0.9937\n",
            "Epoch 373/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1706 - acc: 0.9922 - val_loss: 0.1484 - val_acc: 0.9937\n",
            "Epoch 374/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1700 - acc: 0.9922 - val_loss: 0.1478 - val_acc: 0.9937\n",
            "Epoch 375/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1694 - acc: 0.9922 - val_loss: 0.1472 - val_acc: 0.9937\n",
            "Epoch 376/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1688 - acc: 0.9922 - val_loss: 0.1466 - val_acc: 0.9937\n",
            "Epoch 377/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1682 - acc: 0.9922 - val_loss: 0.1460 - val_acc: 0.9937\n",
            "Epoch 378/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1676 - acc: 0.9922 - val_loss: 0.1454 - val_acc: 0.9937\n",
            "Epoch 379/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1670 - acc: 0.9922 - val_loss: 0.1448 - val_acc: 0.9937\n",
            "Epoch 380/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1664 - acc: 0.9922 - val_loss: 0.1442 - val_acc: 0.9937\n",
            "Epoch 381/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1658 - acc: 0.9922 - val_loss: 0.1436 - val_acc: 0.9937\n",
            "Epoch 382/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1652 - acc: 0.9922 - val_loss: 0.1431 - val_acc: 0.9937\n",
            "Epoch 383/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1646 - acc: 0.9922 - val_loss: 0.1425 - val_acc: 0.9937\n",
            "Epoch 384/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1640 - acc: 0.9922 - val_loss: 0.1419 - val_acc: 0.9937\n",
            "Epoch 385/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1634 - acc: 0.9922 - val_loss: 0.1413 - val_acc: 0.9937\n",
            "Epoch 386/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1628 - acc: 0.9922 - val_loss: 0.1408 - val_acc: 0.9937\n",
            "Epoch 387/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1622 - acc: 0.9922 - val_loss: 0.1402 - val_acc: 0.9937\n",
            "Epoch 388/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1616 - acc: 0.9922 - val_loss: 0.1396 - val_acc: 0.9937\n",
            "Epoch 389/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1611 - acc: 0.9922 - val_loss: 0.1391 - val_acc: 0.9937\n",
            "Epoch 390/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1605 - acc: 0.9922 - val_loss: 0.1385 - val_acc: 0.9937\n",
            "Epoch 391/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1599 - acc: 0.9922 - val_loss: 0.1380 - val_acc: 0.9937\n",
            "Epoch 392/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1593 - acc: 0.9922 - val_loss: 0.1374 - val_acc: 0.9937\n",
            "Epoch 393/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1588 - acc: 0.9922 - val_loss: 0.1369 - val_acc: 0.9937\n",
            "Epoch 394/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1582 - acc: 0.9922 - val_loss: 0.1363 - val_acc: 0.9937\n",
            "Epoch 395/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1576 - acc: 0.9922 - val_loss: 0.1358 - val_acc: 0.9937\n",
            "Epoch 396/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1571 - acc: 0.9922 - val_loss: 0.1352 - val_acc: 0.9937\n",
            "Epoch 397/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1565 - acc: 0.9922 - val_loss: 0.1347 - val_acc: 0.9937\n",
            "Epoch 398/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1560 - acc: 0.9922 - val_loss: 0.1342 - val_acc: 0.9937\n",
            "Epoch 399/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1554 - acc: 0.9922 - val_loss: 0.1336 - val_acc: 0.9937\n",
            "Epoch 400/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1549 - acc: 0.9922 - val_loss: 0.1331 - val_acc: 0.9937\n",
            "Epoch 401/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1543 - acc: 0.9922 - val_loss: 0.1326 - val_acc: 0.9937\n",
            "Epoch 402/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1538 - acc: 0.9922 - val_loss: 0.1320 - val_acc: 0.9937\n",
            "Epoch 403/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1532 - acc: 0.9922 - val_loss: 0.1315 - val_acc: 0.9937\n",
            "Epoch 404/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1527 - acc: 0.9922 - val_loss: 0.1310 - val_acc: 0.9937\n",
            "Epoch 405/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1521 - acc: 0.9922 - val_loss: 0.1305 - val_acc: 0.9937\n",
            "Epoch 406/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1516 - acc: 0.9922 - val_loss: 0.1300 - val_acc: 0.9937\n",
            "Epoch 407/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1511 - acc: 0.9922 - val_loss: 0.1294 - val_acc: 0.9937\n",
            "Epoch 408/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1505 - acc: 0.9922 - val_loss: 0.1289 - val_acc: 0.9937\n",
            "Epoch 409/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1500 - acc: 0.9922 - val_loss: 0.1284 - val_acc: 0.9937\n",
            "Epoch 410/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1495 - acc: 0.9922 - val_loss: 0.1279 - val_acc: 0.9937\n",
            "Epoch 411/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1489 - acc: 0.9922 - val_loss: 0.1274 - val_acc: 0.9937\n",
            "Epoch 412/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1484 - acc: 0.9922 - val_loss: 0.1269 - val_acc: 0.9937\n",
            "Epoch 413/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1479 - acc: 0.9922 - val_loss: 0.1264 - val_acc: 0.9937\n",
            "Epoch 414/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1474 - acc: 0.9922 - val_loss: 0.1259 - val_acc: 0.9937\n",
            "Epoch 415/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1469 - acc: 0.9922 - val_loss: 0.1254 - val_acc: 0.9937\n",
            "Epoch 416/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1463 - acc: 0.9922 - val_loss: 0.1249 - val_acc: 0.9937\n",
            "Epoch 417/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1458 - acc: 0.9922 - val_loss: 0.1244 - val_acc: 0.9937\n",
            "Epoch 418/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1453 - acc: 0.9922 - val_loss: 0.1239 - val_acc: 0.9937\n",
            "Epoch 419/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1448 - acc: 0.9922 - val_loss: 0.1235 - val_acc: 0.9937\n",
            "Epoch 420/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1443 - acc: 0.9922 - val_loss: 0.1230 - val_acc: 0.9937\n",
            "Epoch 421/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1438 - acc: 0.9922 - val_loss: 0.1225 - val_acc: 0.9937\n",
            "Epoch 422/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1433 - acc: 0.9922 - val_loss: 0.1220 - val_acc: 0.9937\n",
            "Epoch 423/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1428 - acc: 0.9922 - val_loss: 0.1215 - val_acc: 0.9937\n",
            "Epoch 424/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1423 - acc: 0.9922 - val_loss: 0.1211 - val_acc: 0.9937\n",
            "Epoch 425/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1418 - acc: 0.9922 - val_loss: 0.1206 - val_acc: 0.9937\n",
            "Epoch 426/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1413 - acc: 0.9922 - val_loss: 0.1201 - val_acc: 0.9937\n",
            "Epoch 427/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1408 - acc: 0.9922 - val_loss: 0.1197 - val_acc: 0.9937\n",
            "Epoch 428/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1403 - acc: 0.9922 - val_loss: 0.1192 - val_acc: 0.9937\n",
            "Epoch 429/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1399 - acc: 0.9922 - val_loss: 0.1187 - val_acc: 0.9937\n",
            "Epoch 430/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1394 - acc: 0.9922 - val_loss: 0.1183 - val_acc: 0.9937\n",
            "Epoch 431/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1389 - acc: 0.9922 - val_loss: 0.1178 - val_acc: 0.9937\n",
            "Epoch 432/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1384 - acc: 0.9922 - val_loss: 0.1174 - val_acc: 0.9937\n",
            "Epoch 433/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1379 - acc: 0.9922 - val_loss: 0.1169 - val_acc: 0.9937\n",
            "Epoch 434/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1375 - acc: 0.9922 - val_loss: 0.1165 - val_acc: 0.9937\n",
            "Epoch 435/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1370 - acc: 0.9922 - val_loss: 0.1160 - val_acc: 0.9937\n",
            "Epoch 436/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1365 - acc: 0.9922 - val_loss: 0.1156 - val_acc: 0.9937\n",
            "Epoch 437/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1361 - acc: 0.9922 - val_loss: 0.1151 - val_acc: 0.9937\n",
            "Epoch 438/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1356 - acc: 0.9922 - val_loss: 0.1147 - val_acc: 0.9937\n",
            "Epoch 439/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1351 - acc: 0.9922 - val_loss: 0.1143 - val_acc: 0.9937\n",
            "Epoch 440/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1347 - acc: 0.9922 - val_loss: 0.1138 - val_acc: 0.9937\n",
            "Epoch 441/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1342 - acc: 0.9922 - val_loss: 0.1134 - val_acc: 0.9937\n",
            "Epoch 442/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1338 - acc: 0.9922 - val_loss: 0.1130 - val_acc: 0.9937\n",
            "Epoch 443/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1333 - acc: 0.9922 - val_loss: 0.1125 - val_acc: 0.9937\n",
            "Epoch 444/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1328 - acc: 0.9922 - val_loss: 0.1121 - val_acc: 0.9937\n",
            "Epoch 445/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1324 - acc: 0.9922 - val_loss: 0.1117 - val_acc: 0.9937\n",
            "Epoch 446/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1319 - acc: 0.9922 - val_loss: 0.1112 - val_acc: 0.9937\n",
            "Epoch 447/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1315 - acc: 0.9922 - val_loss: 0.1108 - val_acc: 0.9937\n",
            "Epoch 448/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1311 - acc: 0.9922 - val_loss: 0.1104 - val_acc: 0.9937\n",
            "Epoch 449/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1306 - acc: 0.9922 - val_loss: 0.1100 - val_acc: 0.9937\n",
            "Epoch 450/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1302 - acc: 0.9922 - val_loss: 0.1096 - val_acc: 0.9937\n",
            "Epoch 451/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1297 - acc: 0.9922 - val_loss: 0.1092 - val_acc: 0.9937\n",
            "Epoch 452/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1293 - acc: 0.9922 - val_loss: 0.1088 - val_acc: 0.9937\n",
            "Epoch 453/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1289 - acc: 0.9922 - val_loss: 0.1083 - val_acc: 0.9937\n",
            "Epoch 454/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1284 - acc: 0.9922 - val_loss: 0.1079 - val_acc: 0.9937\n",
            "Epoch 455/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1280 - acc: 0.9922 - val_loss: 0.1075 - val_acc: 0.9937\n",
            "Epoch 456/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1276 - acc: 0.9922 - val_loss: 0.1071 - val_acc: 0.9937\n",
            "Epoch 457/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1272 - acc: 0.9922 - val_loss: 0.1067 - val_acc: 0.9937\n",
            "Epoch 458/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1267 - acc: 0.9922 - val_loss: 0.1063 - val_acc: 0.9937\n",
            "Epoch 459/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1263 - acc: 0.9922 - val_loss: 0.1059 - val_acc: 0.9937\n",
            "Epoch 460/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1259 - acc: 0.9922 - val_loss: 0.1055 - val_acc: 0.9937\n",
            "Epoch 461/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1255 - acc: 0.9922 - val_loss: 0.1052 - val_acc: 0.9937\n",
            "Epoch 462/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1251 - acc: 0.9922 - val_loss: 0.1048 - val_acc: 0.9937\n",
            "Epoch 463/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1246 - acc: 0.9922 - val_loss: 0.1044 - val_acc: 0.9937\n",
            "Epoch 464/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1242 - acc: 0.9922 - val_loss: 0.1040 - val_acc: 0.9937\n",
            "Epoch 465/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1238 - acc: 0.9922 - val_loss: 0.1036 - val_acc: 0.9937\n",
            "Epoch 466/500\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.1234 - acc: 0.9922 - val_loss: 0.1032 - val_acc: 0.9937\n",
            "Epoch 467/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1230 - acc: 0.9922 - val_loss: 0.1029 - val_acc: 0.9937\n",
            "Epoch 468/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1226 - acc: 0.9922 - val_loss: 0.1025 - val_acc: 0.9937\n",
            "Epoch 469/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1222 - acc: 0.9922 - val_loss: 0.1021 - val_acc: 0.9937\n",
            "Epoch 470/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1218 - acc: 0.9922 - val_loss: 0.1017 - val_acc: 0.9937\n",
            "Epoch 471/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1214 - acc: 0.9922 - val_loss: 0.1014 - val_acc: 0.9937\n",
            "Epoch 472/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1210 - acc: 0.9922 - val_loss: 0.1010 - val_acc: 0.9937\n",
            "Epoch 473/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1206 - acc: 0.9922 - val_loss: 0.1006 - val_acc: 0.9937\n",
            "Epoch 474/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1202 - acc: 0.9922 - val_loss: 0.1003 - val_acc: 0.9937\n",
            "Epoch 475/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1198 - acc: 0.9922 - val_loss: 0.0999 - val_acc: 0.9937\n",
            "Epoch 476/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1195 - acc: 0.9922 - val_loss: 0.0995 - val_acc: 0.9937\n",
            "Epoch 477/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1191 - acc: 0.9922 - val_loss: 0.0992 - val_acc: 0.9937\n",
            "Epoch 478/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1187 - acc: 0.9922 - val_loss: 0.0988 - val_acc: 0.9937\n",
            "Epoch 479/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1183 - acc: 0.9922 - val_loss: 0.0985 - val_acc: 0.9937\n",
            "Epoch 480/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1179 - acc: 0.9922 - val_loss: 0.0981 - val_acc: 0.9937\n",
            "Epoch 481/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1176 - acc: 0.9922 - val_loss: 0.0978 - val_acc: 0.9937\n",
            "Epoch 482/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1172 - acc: 0.9922 - val_loss: 0.0974 - val_acc: 0.9937\n",
            "Epoch 483/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1168 - acc: 0.9922 - val_loss: 0.0971 - val_acc: 0.9937\n",
            "Epoch 484/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1164 - acc: 0.9922 - val_loss: 0.0967 - val_acc: 0.9937\n",
            "Epoch 485/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1161 - acc: 0.9922 - val_loss: 0.0964 - val_acc: 0.9937\n",
            "Epoch 486/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1157 - acc: 0.9922 - val_loss: 0.0960 - val_acc: 0.9937\n",
            "Epoch 487/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1153 - acc: 0.9922 - val_loss: 0.0957 - val_acc: 0.9937\n",
            "Epoch 488/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1150 - acc: 0.9922 - val_loss: 0.0953 - val_acc: 0.9937\n",
            "Epoch 489/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1146 - acc: 0.9922 - val_loss: 0.0950 - val_acc: 0.9937\n",
            "Epoch 490/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1142 - acc: 0.9922 - val_loss: 0.0947 - val_acc: 0.9937\n",
            "Epoch 491/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1139 - acc: 0.9922 - val_loss: 0.0943 - val_acc: 0.9937\n",
            "Epoch 492/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1135 - acc: 0.9922 - val_loss: 0.0940 - val_acc: 0.9937\n",
            "Epoch 493/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1132 - acc: 0.9922 - val_loss: 0.0937 - val_acc: 0.9937\n",
            "Epoch 494/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1128 - acc: 0.9922 - val_loss: 0.0933 - val_acc: 0.9937\n",
            "Epoch 495/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1125 - acc: 0.9922 - val_loss: 0.0930 - val_acc: 0.9937\n",
            "Epoch 496/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1121 - acc: 0.9922 - val_loss: 0.0927 - val_acc: 0.9937\n",
            "Epoch 497/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1118 - acc: 0.9922 - val_loss: 0.0924 - val_acc: 0.9937\n",
            "Epoch 498/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1114 - acc: 0.9922 - val_loss: 0.0921 - val_acc: 0.9937\n",
            "Epoch 499/500\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1111 - acc: 0.9922 - val_loss: 0.0917 - val_acc: 0.9937\n",
            "Epoch 500/500\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1107 - acc: 0.9922 - val_loss: 0.0914 - val_acc: 0.9937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes model\n",
        "nb =GaussianNB()\n",
        "model_c = nb.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "JiI4RxTwpFLF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = x[300000:310000]\n",
        "test_y = y[300000:310000]\n",
        "test_x[df_num.columns] = ss.fit_transform(test_x[df_num.columns])"
      ],
      "metadata": {
        "id": "SAldYU2pipeS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "pedict_y = model_c.predict(test_x)\n",
        "#ppy = [1 if py > 0.5 else 0 for py in pedict_y[:,0]]     \n",
        "ppy = [1 if py > 0.5 else 0 for py in pedict_y]              \n",
        "acc = precision_recall_fscore_support(test_y.values,np.asarray(ppy),average='binary')\n",
        "\n",
        "acc"
      ],
      "metadata": {
        "id": "LJLPvy2Jj4gG",
        "outputId": "4fb8e608-a294-4ef6-b857-6fe2bb45b37e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.15873015873015872, 0.5128205128205128, 0.2424242424242424, None)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_y,ppy))"
      ],
      "metadata": {
        "id": "8MMx2CoDlcQI",
        "outputId": "caed9d9d-529b-4f5f-d2a5-04de96a49215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      9961\n",
            "           1       0.16      0.51      0.24        39\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.58      0.75      0.62     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "f1s = []\n",
        "batch_size = 20000\n",
        "batch = math.ceil(x[300000:-1].shape[0]/batch_size)\n",
        "for i in range(batch):\n",
        "    ux = x[300000:-1][i*batch_size:(i+1)*batch_size]\n",
        "    uy = y[300000:-1][i*batch_size:(i+1)*batch_size]\n",
        "    predict_y = model_c.predict(ux)\n",
        "    ppy = [1 if py > 0.5 else 0 for py in predict_y]       \n",
        "    f1 = precision_recall_fscore_support(uy, np.asarray(ppy),average='binary')\n",
        "    print(\"f1:\",f1[2])\n",
        "    f1s.append(f1[2])"
      ],
      "metadata": {
        "id": "uCYSv-lMlmha",
        "outputId": "579444b1-fded-46ee-8589-9fbc5b43a955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1: 0.004589444278160232\n",
            "f1: 0.006876276844885147\n",
            "f1: 0.009058782539445523\n",
            "f1: 0.00846402788150361\n",
            "f1: 0.010741993236522777\n",
            "f1: 0.007769698177109274\n",
            "f1: 0.008761449621664676\n",
            "f1: 0.003693167639866248\n",
            "f1: 0.0114342530449913\n",
            "f1: 0.006876276844885147\n",
            "f1: 0.006379585326953748\n",
            "f1: 0.009256955158512914\n",
            "f1: 0.007372720932549566\n",
            "f1: 0.01212603120962131\n",
            "f1: 0.012323593718942556\n",
            "f1: 0.012323593718942556\n",
            "f1: 0.012521116963132267\n",
            "f1: 0.011335388286765438\n",
            "f1: 0.014592743336476895\n",
            "f1: 0.014789815871755423\n",
            "f1: 0.012422360248447204\n",
            "f1: 0.007571229328551504\n",
            "f1: 0.009256955158512914\n",
            "f1: 0.013113451221935229\n",
            "f1: 0.00856317833316738\n",
            "f1: 0.008166517279155463\n",
            "f1: 0.008860570461446561\n",
            "f1: 0.004589444278160232\n",
            "f1: 0.008166517279155463\n",
            "f1: 0.010049251281030794\n",
            "f1: 0.008662318912729625\n",
            "f1: 0.013804061770693678\n",
            "f1: 0.014297061159650515\n",
            "f1: 0.013508144616607072\n",
            "f1: 0.010445162894802289\n",
            "f1: 0.014395631670389675\n",
            "f1: 0.012521116963132267\n",
            "f1: 0.014297061159650515\n",
            "f1: 0.0162666137671097\n",
            "f1: 0.007769698177109274\n",
            "f1: 0.00846402788150361\n",
            "f1: 0.008959681433549029\n",
            "f1: 0.00767046869552224\n",
            "f1: 0.01715163832845883\n",
            "f1: 0.015676158349042565\n",
            "f1: 0.013409485969704494\n",
            "f1: 0.00965318206697517\n",
            "f1: 0.009356026674629243\n",
            "f1: 0.008166517279155463\n",
            "f1: 0.01734820322180917\n",
            "f1: 0.006379585326953748\n",
            "f1: 0.01014824395582529\n",
            "f1: 0.008265697355972712\n",
            "f1: 0.006578291637595933\n",
            "f1: 0.008166517279155463\n",
            "f1: 0.00767046869552224\n",
            "f1: 0.013409485969704494\n",
            "f1: 0.007571229328551504\n",
            "f1: 0.007273451900562946\n",
            "f1: 0.008959681433549029\n",
            "f1: 0.010544116184223615\n",
            "f1: 0.008761449621664676\n",
            "f1: 0.009752214150661758\n",
            "f1: 0.012521116963132267\n",
            "f1: 0.010247226782072327\n",
            "f1: 0.010939830929885628\n",
            "f1: 0.008959681433549029\n",
            "f1: 0.009554140127388535\n",
            "f1: 0.005982053838484547\n",
            "f1: 0.011137629276054096\n",
            "f1: 0.004589444278160232\n",
            "f1: 0.005982053838484547\n",
            "f1: 0.007074884161227642\n",
            "f1: 0.004788507581803671\n",
            "f1: 0.004489897730107258\n",
            "f1: 0.0019980019980019984\n",
            "f1: 0.0\n",
            "f1: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(f1s)"
      ],
      "metadata": {
        "id": "1BDlT0TIrWTh",
        "outputId": "ffe3c2d0-a8f3-4f92-e002-8217a6815e1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f325438c350>]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}